{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SJtWtxz-5x8",
        "outputId": "edf3e655-7b99-47e4-d0d9-54a0d8d3a033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'conversational-movies'...\n",
            "remote: Enumerating objects: 85, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 85 (delta 15), reused 26 (delta 9), pack-reused 51\u001b[K\n",
            "Unpacking objects: 100% (85/85), 136.24 MiB | 8.87 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/sergey-volokhin/conversational-movies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Whoosh"
      ],
      "metadata": {
        "id": "62SJCQpF_1MW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence_transformers"
      ],
      "metadata": {
        "id": "AvHLR8eg_4Cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "id": "02cubasnAGpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy"
      ],
      "metadata": {
        "id": "24pzAxAkAJgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scipy"
      ],
      "metadata": {
        "id": "B0vB0nNwAMOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tqdm"
      ],
      "metadata": {
        "id": "9w0R9qrNAPPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit_surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-UK7eAAASZo",
        "outputId": "e9af7254-43eb-4e1f-dac1-085544937db9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit_surprise\n",
            "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.0/772.0 KB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_surprise) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit_surprise) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit_surprise) (1.10.1)\n",
            "Building wheels for collected packages: scikit_surprise\n",
            "  Building wheel for scikit_surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit_surprise: filename=scikit_surprise-1.1.3-cp38-cp38-linux_x86_64.whl size=3366568 sha256=1b6192591c4083e5541b2cbb2318920d5497179afd904acd52ce008ed4ae9e68\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/db/86/2c18183a80ba05da35bf0fb7417aac5cddbd93bcb1b92fd3ea\n",
            "Successfully built scikit_surprise\n",
            "Installing collected packages: scikit_surprise\n",
            "Successfully installed scikit_surprise-1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit_learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hoydZ1IAUZs",
        "outputId": "ef50ade6-3030-4b5c-f3f2-dff04a3d050f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit_learn in /usr/local/lib/python3.8/dist-packages (1.2.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (1.22.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (1.10.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/conversational-movies/indexing.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqzlPkiE_PV4",
        "outputId": "ba590098-7c45-4ec2-e51d-73b0bc506aa9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adding reviews into index: 100% 715766/715766 [06:58<00:00, 1708.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/conversational-movies/dataset.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pos_lRgCEw0q",
        "outputId": "eb849dc6-045e-490e-e8b3-42362b717478"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-07 22:00:18.962369: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-07 22:00:20.207852: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-07 22:00:20.208040: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-07 22:00:20.208064: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/conversational-movies/model.py"
      ],
      "metadata": {
        "id": "DTO0P7y1DQfu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/conversational-movies/main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzJC3We1En2k",
        "outputId": "509c6a5d-48b3-45b5-9c84-e36733118f77"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-07 22:05:41.734918: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-07 22:05:43.565767: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-07 22:05:43.565914: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-07 22:05:43.565933: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "INFO: 22:05:45 - Load pretrained SentenceTransformer: all-mpnet-base-v2\n",
            "INFO: 22:05:47 - Use pytorch device: cpu\n",
            "INFO: 22:05:51 - Indexing reviews\n",
            "adding reviews into index: 100% 715766/715766 [07:02<00:00, 1694.01it/s]\n",
            "INFO: 22:12:53 - Committing reviews. This will take a while\n",
            "INFO: 22:24:51 - Fitting the estimator\n",
            "INFO: 22:26:22 - Estimator fitted\n",
            "INFO: 22:26:22 - sentiment estimator results:\n",
            "INFO: 22:26:22 - RMSE: 0.8013\n",
            "INFO: 22:26:22 -  MAE: 0.6258\n",
            "INFO: 22:26:23 -  R^2: 0.7220\n",
            "INFO: 22:30:17 - training knn\n",
            "INFO: 22:30:32 - RMSE for CF: 1.2076\n",
            "INFO: 22:30:32 -  MAE for CF: 0.9419\n",
            "INFO: 22:30:32 - getting user embedding\n",
            "INFO: 22:37:15 - getting critic embedding\n",
            "critics_emb: 100% 236/236 [1:39:37<00:00, 25.33s/it]\n",
            "metadata features:  68% 160/236 [06:28<01:28,  1.16s/it]WARNING: 00:23:21 - no people for star_wars_episode_vii_the_force_awakens\n",
            "metadata features: 100% 236/236 [09:37<00:00,  2.45s/it]\n",
            "INFO: 00:26:33 - getting average metrics on 100 GradientBoostingRegressors\n",
            "INFO: 00:26:33 - avg RMSE: 1.1138, std: 0.1314\n",
            "INFO: 00:26:33 - avg MAE:  0.8625, std: 0.1256\n",
            "INFO: 00:26:33 - RMSE: 1.0227\n",
            "INFO: 00:26:33 -  MAE: 0.7832\n"
          ]
        }
      ]
    }
  ]
}